{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Partial-Order (HPO) Model Simulation\n",
    "\n",
    "This document provides a comprehensive guide to simulating data from a **Hierarchical Partial-Order (HPO) Model**. The HPO model is designed to generate hierarchical structures of partial orders based on latent variables influenced by multiple assessors. This simulation accounts for global latent scores, assessor-specific deviations, and observed ranking data within specified choice sets.\n",
    "\n",
    "1: Global Latent U:U(0)∼N(0,Σ ρ​)\n",
    "2: Assessor-Specific Latent Scores\n",
    "3:Transformation to Preference Scores\n",
    "4.Generation of Partial Orders for each η(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion with Geoff abou this script:\n",
    "1. The hierachical partial order work \n",
    "\ta. will yi contain a full rank for partial order or only \n",
    "\tb. talk about the data structure \n",
    "\tc. when we do inference, what are we inferreing to? How to generate the choisen set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import networkx as nx\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Dict, Any\n",
    "import sys as sys\n",
    "\n",
    "# Make sure these paths and imports match your local project structure\n",
    "sys.path.append('../src/utils')  # Example path\n",
    "from po_fun import BasicUtils, StatisticalUtils#\n",
    "from mallow_function import Mallows\n",
    "#from po_accelerator import LogLikelihoodCache\n",
    "from typing import Dict, List\n",
    "\n",
    "# Transform Eta change the G function \n",
    "# The initial setting is not correct, we need to have the O_i variable , and then we could generate the hierachical relationship out\n",
    "\n",
    "# Then deploy the partial order relationship \n",
    "\n",
    "# Peform the MCMC simulation alogrithem and think the method about how to write it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def G_inv(p):\n",
    "    # Gumbel quantile function\n",
    "    # Safeguard tiny p to avoid log(0)\n",
    "    eps = 1e-15\n",
    "    p_safe = np.clip(p, eps, 1 - eps)\n",
    "    return -np.log(-np.log(p_safe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = [0, 1, 2, 3, 4, 5] ## This is the total list \n",
    "assessors = [1, 2, 3]\n",
    "# (Sometimes called the \"leaf\" sets M_a in the partial-order hierarchy.)\n",
    "M_a_list = [\n",
    "    [0, 2, 4],   # M_1\n",
    "    [1, 2, 3],   # M_2\n",
    "    [1, 3, 4]    # M_3\n",
    "]\n",
    "\n",
    "# For each assessor a, the list of choice sets O_{a,i}\n",
    "# Meaning: in each \"task\" or \"batch\", assessor a was asked to rank this subset.\n",
    "# We'll store them in a dictionary keyed by assessor, \n",
    "# each value is a list of subsets (choice sets).\n",
    "O_a_i_dict = {\n",
    "    1: [\n",
    "        [0, 2, 4],\n",
    "        [0, 2]\n",
    "    ],\n",
    "    2: [\n",
    "        [1, 2,5],\n",
    "        [1, 3],\n",
    "        [1,4,5]\n",
    "    ],\n",
    "    3: [\n",
    "        [1, 3],\n",
    "        [1, 3, 4],\n",
    "        [2,4,5]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Observed orders y_{a,i} (one for each choice set above).\n",
    "# For instance, y_{1,0} is an order of [0,4,2] (lowest rank first or highest first, depending on convention).\n",
    "# We'll store these in the same dictionary shape.\n",
    "# These are \"real\" or \"observed\" orders for the subsets O_{a,i}.\n",
    "y_a_i_dict = {\n",
    "    1: [\n",
    "        [0, 4, 2],   # observed order for subset [0,2,4]\n",
    "        [0, 2]       # observed order for subset [0,2]\n",
    "    ],\n",
    "    2: [\n",
    "        [1, 2],      # observed order for subset [1,2],will yi contain a full rank for partial order \n",
    "        [3, 1]       # observed order for subset [1,3]\n",
    "        # [1, 4]       # observed order for subset [1,4,5]\n",
    "    ],\n",
    "    3: [\n",
    "        [3, 1],      # observed order for subset [1,3]\n",
    "        [4, 3, 1],   # observed order for subset [1,3,4]\n",
    "        [5,4,2]\n",
    "    ]\n",
    "}\n",
    "\n",
    "alpha = np.array([0.5, -0.2, 0.3, 0.1, 0.0, 1.2]) # The characteristic vector for the object, which is a score , alpha is beta*X , alpha is the global variable and need M0 dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2 \n",
    "rho = 0.9 # Should follow a beta distributino, let's assume this first \n",
    "tau = 0.8# should follow a beta distributino, let's assume this first "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_HPO_with_tasks(\n",
    "    M0: List[int],\n",
    "    assessors: List[int],\n",
    "    M_a_list: List[List[int]],\n",
    "    O_a_i_dict: Dict[int, List[List[int]]],\n",
    "    alpha: np.ndarray,            # Must be non-None and length = len(M0)\n",
    "    K: int,\n",
    "    rho: float,\n",
    "    tau: float,\n",
    "    random_seed: int = 42\n",
    "):\n",
    " \n",
    "    # ----------------------------\n",
    "    # 1) Setup: random seed & covariance\n",
    "    # ----------------------------\n",
    "    rng = np.random.default_rng(random_seed)  # single global RNG\n",
    "    random.seed(random_seed)                  # for any other random usage\n",
    "\n",
    "    # Build the correlation matrix Sigma_rho (compound-symmetric)\n",
    "    Sigma_rho = np.full((K, K), rho, dtype=float)\n",
    "    np.fill_diagonal(Sigma_rho, 1.0)\n",
    "\n",
    "    # Validate alpha length\n",
    "    n_global = len(M0)\n",
    "    if len(alpha) != n_global:\n",
    "        raise ValueError(\n",
    "            f\"alpha must have length {n_global}, but got length {len(alpha)}\"\n",
    "        )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2) Global Latent U^(0)\n",
    "    # ----------------------------\n",
    "    mvn_global = multivariate_normal(mean=np.zeros(K), cov=Sigma_rho)\n",
    "    U0 = mvn_global.rvs(size=n_global)  # shape: (n_global, K)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3) Assessor-level Latents\n",
    "    # ----------------------------\n",
    "    U_a_list = []\n",
    "    eta_a_list = []\n",
    "    h_a_list = []\n",
    "    h_a_i = {a: {} for a in assessors}  # partial orders restricted to tasks\n",
    "\n",
    "    for idx, a in enumerate(assessors):\n",
    "        # Items for this assessor:\n",
    "        Ma = M_a_list[idx]\n",
    "        n_a = len(Ma)\n",
    "\n",
    "        # For j in M_a: U^(a)_j ~ N( tau*U^(0)_j, (1 - tau^2)*Sigma_rho )\n",
    "        # We do it based on each object j in this question.\n",
    "        Ua = np.zeros((n_a, K), dtype=float)\n",
    "        for i_loc, j_global in enumerate(Ma):\n",
    "            mean_vec = tau * U0[j_global, :]\n",
    "            cov_mat  = (1 - tau**2) * Sigma_rho\n",
    "            Ua[i_loc, :] = rng.multivariate_normal(mean=mean_vec, cov=cov_mat)\n",
    "        U_a_list.append(Ua)\n",
    "\n",
    "        # Transform to Gumbel-based eta^(a)\n",
    "        eta_a = np.zeros_like(Ua)\n",
    "        for i_loc, j_global in enumerate(Ma):\n",
    "            # step 1: Gaussian -> Uniform(0,1)\n",
    "            p_vec = norm.cdf(Ua[i_loc, :])\n",
    "            # step 2: Uniform(0,1) -> Gumbel -> + alpha\n",
    "            gumbel_vec = np.array([G_inv(p) for p in p_vec])\n",
    "            eta_a[i_loc, :] = gumbel_vec + alpha[j_global]\n",
    "        eta_a_list.append(eta_a)\n",
    "\n",
    "        # partial order h^(a)\n",
    "        h_a = BasicUtils.generate_partial_order(eta_a)\n",
    "        h_a_list.append(h_a)\n",
    "\n",
    "        # Restrict partial order to each choice set O_{a,i}\n",
    "        O_list = O_a_i_dict.get(a, [])\n",
    "        for i_task, subset in enumerate(O_list):\n",
    "            subset_indices_in_Ma = []\n",
    "            for item_j in subset:\n",
    "                if item_j in Ma:\n",
    "                    local_idx = Ma.index(item_j)\n",
    "                    subset_indices_in_Ma.append(local_idx)\n",
    "\n",
    "            sub_size = len(subset_indices_in_Ma)\n",
    "            h_sub = np.zeros((sub_size, sub_size), dtype=int)\n",
    "            for r, i_loc_ in enumerate(subset_indices_in_Ma):\n",
    "                for c, j_loc_ in enumerate(subset_indices_in_Ma):\n",
    "                    h_sub[r, c] = h_a[i_loc_, j_loc_]\n",
    "            \n",
    "            h_a_i[a][i_task] = h_sub\n",
    "\n",
    "    # ----------------------------\n",
    "    # Return results\n",
    "    # ----------------------------\n",
    "    results = {\n",
    "        'U0': U0,         # shape (|M0|, K)\n",
    "        'U_a': U_a_list,  # list of length = # of assessors\n",
    "        'eta_a': eta_a_list,\n",
    "        'h_a': h_a_list,\n",
    "        'h_a_i': h_a_i\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulate_HPO_with_tasks(\n",
    "    M0=M0,\n",
    "    assessors=assessors,\n",
    "    M_a_list=M_a_list,\n",
    "    O_a_i_dict=O_a_i_dict,\n",
    "    alpha=alpha,         # Not None\n",
    "    K=2,\n",
    "    rho=0.3,\n",
    "    tau=0.8,\n",
    "    random_seed=2025     # Global random seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Global U^(0) ---\n",
      "[[-0.3230209  -0.46351352]\n",
      " [ 1.80666393 -0.03128583]\n",
      " [-0.37366743 -0.69472578]\n",
      " [ 1.23964294 -0.59862485]\n",
      " [ 0.45811139 -0.46849712]\n",
      " [-0.4692466   1.25485964]]\n",
      "\n",
      "Assessor 1\n",
      "  U^(a):\n",
      " [[ 0.80685359  0.71291742]\n",
      " [ 0.36260816 -0.69588587]\n",
      " [ 1.27601961  1.0781068 ]]\n",
      "  eta^(a):\n",
      " [[ 1.94576989  1.8029057 ]\n",
      " [ 1.11223189 -0.04618557]\n",
      " [ 2.24013954  1.88785393]]\n",
      "  h^(a) adjacency:\n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]]\n",
      "  Task 0, O_(1, 0) = [0, 2, 4]\n",
      "    restricted adjacency:\n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]]\n",
      "  Task 1, O_(1, 1) = [0, 2]\n",
      "    restricted adjacency:\n",
      " [[0 1]\n",
      " [0 0]]\n",
      "\n",
      "Assessor 2\n",
      "  U^(a):\n",
      " [[ 1.71805525  0.43724394]\n",
      " [-0.74210301 -0.79156413]\n",
      " [ 0.8536984  -0.14923463]]\n",
      "  eta^(a):\n",
      " [[ 2.92720027  0.71149668]\n",
      " [-0.08796545 -0.13200557]\n",
      " [ 1.61892356  0.29915039]]\n",
      "  h^(a) adjacency:\n",
      " [[0 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]]\n",
      "  Task 0, O_(2, 0) = [1, 2, 5]\n",
      "    restricted adjacency:\n",
      " [[0 1]\n",
      " [0 0]]\n",
      "  Task 1, O_(2, 1) = [1, 3]\n",
      "    restricted adjacency:\n",
      " [[0 1]\n",
      " [0 0]]\n",
      "  Task 2, O_(2, 2) = [1, 4, 5]\n",
      "    restricted adjacency:\n",
      " [[0]]\n",
      "\n",
      "Assessor 3\n",
      "  U^(a):\n",
      " [[ 0.98118134 -0.06392255]\n",
      " [ 1.92994526  0.18072577]\n",
      " [-0.34804909  0.99502497]]\n",
      "  eta^(a):\n",
      " [[ 1.52466962  0.09375373]\n",
      " [ 3.70554374  0.68138063]\n",
      " [-0.01081295  1.7476133 ]]\n",
      "  h^(a) adjacency:\n",
      " [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]]\n",
      "  Task 0, O_(3, 0) = [1, 3]\n",
      "    restricted adjacency:\n",
      " [[0 0]\n",
      " [1 0]]\n",
      "  Task 1, O_(3, 1) = [1, 3, 4]\n",
      "    restricted adjacency:\n",
      " [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]]\n",
      "  Task 2, O_(3, 2) = [2, 4, 5]\n",
      "    restricted adjacency:\n",
      " [[0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Global U^(0) ---\")\n",
    "print(results['U0'])\n",
    "\n",
    "for idx, a in enumerate(assessors):\n",
    "    print(f\"\\nAssessor {a}\")\n",
    "    print(\"  U^(a):\\n\", results['U_a'][idx])\n",
    "    print(\"  eta^(a):\\n\", results['eta_a'][idx])\n",
    "    print(\"  h^(a) adjacency:\\n\", results['h_a'][idx])\n",
    "\n",
    "    # Show restricted partial orders\n",
    "    for i_task, O_subset in enumerate(O_a_i_dict[a]):\n",
    "        print(f\"  Task {i_task}, O_{a,i_task} = {O_subset}\")\n",
    "        print(\"    restricted adjacency:\\n\", results['h_a_i'][a][i_task])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-partial-orders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
