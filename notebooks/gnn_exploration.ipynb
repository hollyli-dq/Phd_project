{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp39-cp39-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /home/doli/miniconda3/envs/bayesian-partial-orders/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in /home/doli/miniconda3/envs/bayesian-partial-orders/lib/python3.9/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/doli/miniconda3/envs/bayesian-partial-orders/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/doli/miniconda3/envs/bayesian-partial-orders/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/doli/miniconda3/envs/bayesian-partial-orders/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading triton-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/doli/miniconda3/envs/bayesian-partial-orders/lib/python3.9/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/doli/miniconda3/envs/bayesian-partial-orders/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.5.1-cp39-cp39-manylinux1_x86_64.whl (906.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp39-cp39-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed fsspec-2024.10.0 mpmath-1.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch torchvision numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/utils')  # Adjust this path based on your directory structure\n",
    "\n",
    "from po_fun import PO_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(num_samples, n_nodes, K):\n",
    "    \"\"\"\n",
    "    Generates synthetic partial order data and corresponding log(#LE) values.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_samples: Number of samples to generate.\n",
    "    - n_nodes: Number of nodes in each partial order.\n",
    "    - K: Number of dimensions for latent variables Z.\n",
    "    \n",
    "    Returns:\n",
    "    - h_matrices: List of adjacency matrices representing partial orders.\n",
    "    - log_LEs: List of log(#LE) values.\n",
    "    \"\"\"\n",
    "    h_matrices = []\n",
    "    log_LEs = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Randomly generate a DAG\n",
    "        h = np.zeros((n_nodes, n_nodes), dtype=int)\n",
    "        edges = []\n",
    "        for i in range(n_nodes):\n",
    "            for j in range(i+1, n_nodes):\n",
    "                if random.random() < 0.3:  # 30% chance of an edge\n",
    "                    h[i, j] = 1\n",
    "                    edges.append((i, j))\n",
    "        \n",
    "        # Ensure transitivity (simple transitive closure)\n",
    "        for k in range(n_nodes):\n",
    "            for i in range(n_nodes):\n",
    "                for j in range(n_nodes):\n",
    "                    if h[i, k] and h[k, j]:\n",
    "                        h[i, j] = 1\n",
    "        \n",
    "        h_matrices.append(h)\n",
    "        \n",
    "        # Estimate #LEs (for synthetic purposes, use a random value)\n",
    "        # In practice, compute the exact or approximate number of linear extensions\n",
    "        # Here, we use a random log_LE between 0 and 10\n",
    "        log_LE = np.log(PO_util.nle(h))\n",
    "        log_LEs.append(log_LE)\n",
    "    \n",
    "    return h_matrices, log_LEs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialOrderDataset(Dataset):\n",
    "    def __init__(self, h_matrices, log_LEs):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with partial order matrices and log(#LE) values.\n",
    "        \n",
    "        Parameters:\n",
    "        - h_matrices: List of adjacency matrices (NumPy arrays).\n",
    "        - log_LEs: List of corresponding log(#LE) values.\n",
    "        \"\"\"\n",
    "        self.h_matrices = h_matrices\n",
    "        self.log_LEs = log_LEs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.h_matrices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the h matrix and log_LE for a given index.\n",
    "        \n",
    "        Returns:\n",
    "        - h_tensor: Tensor representation of the h matrix.\n",
    "        - log_LE: Tensor representation of log(#LE).\n",
    "        \"\"\"\n",
    "        h = self.h_matrices[idx]\n",
    "        log_LE = self.log_LEs[idx]\n",
    "        \n",
    "        # Flatten the h matrix and convert to float tensor\n",
    "        h_tensor = torch.tensor(h, dtype=torch.float32).flatten()\n",
    "        log_LE = torch.tensor(log_LE, dtype=torch.float32)\n",
    "        \n",
    "        return h_tensor, log_LE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m K_DIM \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m             \u001b[38;5;66;03m# Number of dimensions for latent variables Z (not directly used here)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generate synthetic data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m h_matrices, log_LEs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_synthetic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNUM_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_NODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Split into training and testing sets (80% train, 20% test)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m split_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m NUM_SAMPLES)\n",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m, in \u001b[0;36mgenerate_synthetic_data\u001b[0;34m(num_samples, n_nodes, K)\u001b[0m\n\u001b[1;32m     34\u001b[0m     h_matrices\u001b[38;5;241m.\u001b[39mappend(h)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Estimate #LEs (for synthetic purposes, use a random value)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# In practice, compute the exact or approximate number of linear extensions\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Here, we use a random log_LE between 0 and 10\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     log_LE \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mPO_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m     log_LEs\u001b[38;5;241m.\u001b[39mappend(log_LE)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h_matrices, log_LEs\n",
      "File \u001b[0;32m~/Desktop/research/coding/BayesianPartialOrders/notebooks/../src/utils/po_fun.py:180\u001b[0m, in \u001b[0;36mPO_util.nle\u001b[0;34m(tr)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tops:\n\u001b[1;32m    179\u001b[0m     trr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(np\u001b[38;5;241m.\u001b[39mdelete(tr, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mPO_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fac \u001b[38;5;241m*\u001b[39m count\n",
      "File \u001b[0;32m~/Desktop/research/coding/BayesianPartialOrders/notebooks/../src/utils/po_fun.py:180\u001b[0m, in \u001b[0;36mPO_util.nle\u001b[0;34m(tr)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tops:\n\u001b[1;32m    179\u001b[0m     trr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(np\u001b[38;5;241m.\u001b[39mdelete(tr, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mPO_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fac \u001b[38;5;241m*\u001b[39m count\n",
      "File \u001b[0;32m~/Desktop/research/coding/BayesianPartialOrders/notebooks/../src/utils/po_fun.py:180\u001b[0m, in \u001b[0;36mPO_util.nle\u001b[0;34m(tr)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tops:\n\u001b[1;32m    179\u001b[0m     trr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(np\u001b[38;5;241m.\u001b[39mdelete(tr, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mPO_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fac \u001b[38;5;241m*\u001b[39m count\n",
      "File \u001b[0;32m~/Desktop/research/coding/BayesianPartialOrders/notebooks/../src/utils/po_fun.py:175\u001b[0m, in \u001b[0;36mPO_util.nle\u001b[0;34m(tr)\u001b[0m\n\u001b[1;32m    173\u001b[0m     j \u001b[38;5;241m=\u001b[39m bots[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    174\u001b[0m     trr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(np\u001b[38;5;241m.\u001b[39mdelete(tr, [i, j], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), [i, j], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fac \u001b[38;5;241m*\u001b[39m \u001b[43mPO_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tops:\n",
      "File \u001b[0;32m~/Desktop/research/coding/BayesianPartialOrders/notebooks/../src/utils/po_fun.py:179\u001b[0m, in \u001b[0;36mPO_util.nle\u001b[0;34m(tr)\u001b[0m\n\u001b[1;32m    177\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tops:\n\u001b[0;32m--> 179\u001b[0m     trr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    180\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m PO_util\u001b[38;5;241m.\u001b[39mnle(trr)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fac \u001b[38;5;241m*\u001b[39m count\n",
      "File \u001b[0;32m~/miniconda3/envs/bayesian-partial-orders/lib/python3.9/site-packages/numpy/lib/function_base.py:5330\u001b[0m, in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   5327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_value:\n\u001b[1;32m   5328\u001b[0m     \u001b[38;5;66;03m# optimization for a single value\u001b[39;00m\n\u001b[1;32m   5329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (obj \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mN \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m N):\n\u001b[0;32m-> 5330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   5331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m is out of bounds for axis \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5332\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (obj, axis, N))\n\u001b[1;32m   5333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (obj \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   5334\u001b[0m         obj \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m N\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "NUM_SAMPLES = 1000    # Total number of samples\n",
    "N_NODES = 10          # Number of nodes in each partial order\n",
    "K_DIM = 5             # Number of dimensions for latent variables Z (not directly used here)\n",
    "\n",
    "# Generate synthetic data\n",
    "h_matrices, log_LEs = generate_synthetic_data(NUM_SAMPLES, N_NODES, K_DIM)\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "split_idx = int(0.8 * NUM_SAMPLES)\n",
    "train_h = h_matrices[:split_idx]\n",
    "train_log_LE = log_LEs[:split_idx]\n",
    "test_h = h_matrices[split_idx:]\n",
    "test_log_LE = log_LEs[split_idx:]\n",
    "\n",
    "# Create Dataset objects\n",
    "train_dataset = PartialOrderDataset(train_h, train_log_LE)\n",
    "test_dataset = PartialOrderDataset(test_h, test_log_LE)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LE_Predictor(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim=128):\n",
    "        \"\"\"\n",
    "        Initializes the neural network.\n",
    "        \n",
    "        Parameters:\n",
    "        - input_size: Size of the input vector (flattened h matrix).\n",
    "        - embedding_dim: Size of the embedding layer.\n",
    "        \"\"\"\n",
    "        super(LE_Predictor, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(input_size, embedding_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(embedding_dim, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.output = nn.Linear(32, 1)  # Predicting a single scalar value\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass.\n",
    "        \n",
    "        Parameters:\n",
    "        - x: Input tensor.\n",
    "        \n",
    "        Returns:\n",
    "        - Output tensor.\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.output(x)\n",
    "        return x.squeeze()  # Remove unnecessary dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine input size\n",
    "INPUT_SIZE = N_NODES * N_NODES  # e.g., 10x10 = 100\n",
    "\n",
    "# Initialize the model\n",
    "model = LE_Predictor(input_size=INPUT_SIZE, embedding_dim=128)\n",
    "\n",
    "# Define the loss function (Mean Squared Error for regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Device configuration (use GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (h_batch, log_LE_batch) in enumerate(train_loader):\n",
    "        h_batch = h_batch.to(device)\n",
    "        log_LE_batch = log_LE_batch.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(h_batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, log_LE_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss over the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for h_batch, log_LE_batch in test_loader:\n",
    "            h_batch = h_batch.to(device)\n",
    "            log_LE_batch = log_LE_batch.to(device)\n",
    "            outputs = model(h_batch)\n",
    "            loss = criterion(outputs, log_LE_batch)\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], \"\n",
    "          f\"Train Loss: {avg_loss:.4f}, \"\n",
    "          f\"Test Loss: {avg_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to evaluate the model and collect predictions\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for h_batch, log_LE_batch in data_loader:\n",
    "            h_batch = h_batch.to(device)\n",
    "            log_LE_batch = log_LE_batch.to(device)\n",
    "            outputs = model(h_batch)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(log_LE_batch.cpu().numpy())\n",
    "    return predictions, actuals\n",
    "\n",
    "# Get predictions and actuals for the test set\n",
    "predictions, actuals = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Convert to NumPy arrays for easier handling\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test R² Score: {r2:.4f}\")\n",
    "\n",
    "# Plotting Predicted vs Actual\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(actuals, predictions, alpha=0.7)\n",
    "plt.xlabel(\"Actual log(#LE)\")\n",
    "plt.ylabel(\"Predicted log(#LE)\")\n",
    "plt.title(\"Actual vs Predicted log(#LE)\")\n",
    "plt.plot([actuals.min(), actuals.max()], [actuals.min(), actuals.max()], 'r--')  # Diagonal line\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-partial-orders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
