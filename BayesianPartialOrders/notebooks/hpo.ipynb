{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Partial-Order (HPO) Model Simulation\n",
    "\n",
    "This document provides a comprehensive guide to simulating data from a **Hierarchical Partial-Order (HPO) Model**. The HPO model is designed to generate hierarchical structures of partial orders based on latent variables influenced by multiple assessors. This simulation accounts for global latent scores, assessor-specific deviations, and observed ranking data within specified choice sets.\n",
    "\n",
    "## Model Overview\n",
    "\n",
    "The Hierarchical Partial-Order (HPO) model operates under the following hierarchical structure:\n",
    "\n",
    "1. **Global Latent Scores**:\n",
    "   \\[\n",
    "   U^{(0)} \\sim \\mathcal{N}(\\mathbf{0}, \\Sigma_\\rho)\n",
    "   \\]\n",
    "   Each item \\( j \\in M_0 \\) has a global latent score \\( U_j^{(0)} \\) drawn from a multivariate normal distribution with mean vector \\( \\mathbf{0} \\) and covariance matrix \\( \\Sigma_\\rho \\).\n",
    "\n",
    "2. **Assessor-Specific Latent Scores**:\n",
    "   \\[\n",
    "   U^{(a)}_j \\mid U^{(0)}_j \\sim \\mathcal{N}(\\tau \\cdot U^{(0)}_j, (1 - \\tau^2) \\cdot \\Sigma_\\rho)\n",
    "   \\]\n",
    "   For each assessor \\( a \\in A \\) and each item \\( j \\in M_a \\subseteq M_0 \\), the assessor-specific latent score \\( U^{(a)}_j \\) is drawn from a multivariate normal distribution centered at \\( \\tau \\cdot U^{(0)}_j \\) with covariance \\( (1 - \\tau^2) \\cdot \\Sigma_\\rho \\).\n",
    "\n",
    "3. **Transformation to Preference Scores**:\n",
    "   \\[\n",
    "   \\eta_j^{(a)} = G^{-1}(\\Phi(U_j^{(a)})) + \\alpha_j\n",
    "   \\]\n",
    "   The latent scores \\( U_j^{(a)} \\) are transformed into preference scores \\( \\eta_j^{(a)} \\) using the inverse Gumbel CDF \\( G^{-1} \\) applied to the standard normal CDF \\( \\Phi(U_j^{(a)}) \\), followed by the addition of item-specific effects \\( \\alpha_j \\).\n",
    "\n",
    "4. **Generation of Partial Orders**:\n",
    "   \\[\n",
    "   h^{(a)} = h(\\eta^{(a)})\n",
    "   \\]\n",
    "   Each preference score matrix \\( \\eta^{(a)} \\) is converted into a partial order \\( h^{(a)} \\) by establishing directed edges between items based on their preference scores across all dimensions.\n",
    "\n",
    "5. **Restriction to Choice Sets**:\n",
    "   Each partial order \\( h^{(a)} \\) is further restricted to smaller choice sets \\( O_{a,i} \\) to reflect observed rankings.\n",
    "\n",
    "## Function: `simulate_HPO_with_tasks`\n",
    "\n",
    "The `simulate_HPO_with_tasks` function encapsulates the simulation process of the HPO model. It generates global and assessor-specific latent scores, transforms them into preference scores, constructs partial orders, and restricts these orders to specified choice sets.\n",
    "\n",
    "### Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import networkx as nx\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Optional, Dict, Any\n",
    "import sys as sys\n",
    "\n",
    "# Make sure these paths and imports match your local project structure\n",
    "sys.path.append('../src/utils')  # Example path\n",
    "from po_fun import BasicUtils, StatisticalUtils#\n",
    "from mallow_function import Mallows\n",
    "#from po_accelerator import LogLikelihoodCache\n",
    "from typing import Dict, List\n",
    "\n",
    "# Transform Eta change the G function \n",
    "# The initial setting is not correct, we need to have the O_i variable , and then we could generate the hierachical relationship out\n",
    "\n",
    "# Then deploy the partial order relationship \n",
    "\n",
    "# Peform the MCMC simulation alogrithem and think the method about how to write it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def G_inv(p):\n",
    "    # Gumbel quantile function\n",
    "    # Safeguard tiny p to avoid log(0)\n",
    "    eps = 1e-15\n",
    "    p_safe = np.clip(p, eps, 1 - eps)\n",
    "    return -np.log(-np.log(p_safe))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = [0, 1, 2, 3, 4, 5] ## This is the total list \n",
    "assessors = [1, 2, 3]\n",
    "# (Sometimes called the \"leaf\" sets M_a in the partial-order hierarchy.)\n",
    "M_a_list = [\n",
    "    [0, 2, 4],   # M_1\n",
    "    [1, 2, 3],   # M_2\n",
    "    [1, 3, 4]    # M_3\n",
    "]\n",
    "\n",
    "# For each assessor a, the list of choice sets O_{a,i}\n",
    "# Meaning: in each \"task\" or \"batch\", assessor a was asked to rank this subset.\n",
    "# We'll store them in a dictionary keyed by assessor, \n",
    "# each value is a list of subsets (choice sets).\n",
    "O_a_i_dict = {\n",
    "    1: [\n",
    "        [0, 2, 4],\n",
    "        [0, 2]\n",
    "    ],\n",
    "    2: [\n",
    "        [1, 2,5],\n",
    "        [1, 3],\n",
    "        [1,4,5]\n",
    "    ],\n",
    "    3: [\n",
    "        [1, 3],\n",
    "        [1, 3, 4],\n",
    "        [2,4,5]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Observed orders y_{a,i} (one for each choice set above).\n",
    "# For instance, y_{1,0} is an order of [0,4,2] (lowest rank first or highest first, depending on convention).\n",
    "# We'll store these in the same dictionary shape.\n",
    "# These are \"real\" or \"observed\" orders for the subsets O_{a,i}.\n",
    "y_a_i_dict = {\n",
    "    1: [\n",
    "        [0, 4, 2],   # observed order for subset [0,2,4]\n",
    "        [0, 2]       # observed order for subset [0,2]\n",
    "    ],\n",
    "    2: [\n",
    "        [1, 2],      # observed order for subset [1,2],will yi contain a full rank for partial order \n",
    "        [3, 1]       # observed order for subset [1,3]\n",
    "        # [1, 4]       # observed order for subset [1,4,5]\n",
    "    ],\n",
    "    3: [\n",
    "        [3, 1],      # observed order for subset [1,3]\n",
    "        [4, 3, 1],   # observed order for subset [1,3,4]\n",
    "        [5,4,2]\n",
    "    ]\n",
    "}\n",
    "\n",
    "alpha = np.array([0.5, -0.2, 0.3, 0.1, 0.0, 1.2]) # The characteristic vector for the object, which is a score , alpha is beta*X , alpha is the global variable and need M0 dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2 \n",
    "rho = 0.9 # Should follow a beta distributino, let's assume this first \n",
    "tau = 0.8# should follow a beta distributino, let's assume this first "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate from the hierarchical partial-order model, requiring:\n",
    "      U^(0) ~ N(0, Sigma_rho),\n",
    "      U^(a) | U^(0) ~ N(tau * U^(0), (1 - tau^2)*Sigma_rho),\n",
    "      eta^(a) = G^-1( Phi(U^(a)) ) + alpha_j,\n",
    "      h^(a)   = partial order from eta^(a).\n",
    "\n",
    "    Then restrict each h^(a) to the smaller choice sets O_{a,i}.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    M0 : List[int]\n",
    "        Global set of items (indices).\n",
    "    assessors : List[int]\n",
    "        List of assessor IDs (1, 2, 3, ...).\n",
    "    M_a_list : List[List[int]]\n",
    "        For each assessor a, which items they rank. Must align with assessors.\n",
    "    O_a_i_dict : Dict[int, List[List[int]]]\n",
    "        For each assessor a, a list of choice sets (subsets).\n",
    "    alpha : np.ndarray\n",
    "    K : int\n",
    "        Dimensionality of latent space.\n",
    "    rho : float\n",
    "        Off-diagonal correlation in compound-symmetric covariance Sigma_rho.\n",
    "    tau : float\n",
    "        Correlation-like parameter in [0, 1].\n",
    "    random_seed : int\n",
    "        Global random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : Dict[str, Any]\n",
    "        Contains:\n",
    "          - 'U0': (|M0| x K) global latent scores,\n",
    "          - 'U_a': list of (|M_a| x K) latents for each assessor a,\n",
    "          - 'eta_a': list of (|M_a| x K) after Gumbel transform + alpha,\n",
    "          - 'h_a': list of adjacency matrices (|M_a| x |M_a|),\n",
    "          - 'h_a_i': dict-of-dicts for partial orders restricted to O_{a,i}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_HPO_with_tasks(\n",
    "    M0: List[int],\n",
    "    assessors: List[int],\n",
    "    M_a_list: List[List[int]],\n",
    "    O_a_i_dict: Dict[int, List[List[int]]],\n",
    "    alpha: np.ndarray,            # Must be non-None and length = len(M0)\n",
    "    K: int,\n",
    "    rho: float,\n",
    "    tau: float,\n",
    "    random_seed: int = 42\n",
    "):\n",
    " \n",
    "    # ----------------------------\n",
    "    # 1) Setup: random seed & covariance\n",
    "    # ----------------------------\n",
    "    rng = np.random.default_rng(random_seed)  # single global RNG\n",
    "    random.seed(random_seed)                  # for any other random usage\n",
    "\n",
    "    # Build the correlation matrix Sigma_rho (compound-symmetric)\n",
    "    Sigma_rho = np.full((K, K), rho, dtype=float)\n",
    "    np.fill_diagonal(Sigma_rho, 1.0)\n",
    "\n",
    "    # Validate alpha length\n",
    "    n_global = len(M0)\n",
    "    if len(alpha) != n_global:\n",
    "        raise ValueError(\n",
    "            f\"alpha must have length {n_global}, but got length {len(alpha)}\"\n",
    "        )\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2) Global Latent U^(0)\n",
    "    # ----------------------------\n",
    "    mvn_global = multivariate_normal(mean=np.zeros(K), cov=Sigma_rho)\n",
    "    U0 = mvn_global.rvs(size=n_global)  # shape: (n_global, K)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3) Assessor-level Latents\n",
    "    # ----------------------------\n",
    "    U_a_list = []\n",
    "    eta_a_list = []\n",
    "    h_a_list = []\n",
    "    h_a_i = {a: {} for a in assessors}  # partial orders restricted to tasks\n",
    "\n",
    "    for idx, a in enumerate(assessors):\n",
    "        # Items for this assessor:\n",
    "        Ma = M_a_list[idx]\n",
    "        n_a = len(Ma)\n",
    "\n",
    "        # For j in M_a: U^(a)_j ~ N( tau*U^(0)_j, (1 - tau^2)*Sigma_rho )\n",
    "        # We do it based on each object j in this question.\n",
    "        Ua = np.zeros((n_a, K), dtype=float)\n",
    "        for i_loc, j_global in enumerate(Ma):\n",
    "            mean_vec = tau * U0[j_global, :]\n",
    "            cov_mat  = (1 - tau**2) * Sigma_rho\n",
    "            Ua[i_loc, :] = rng.multivariate_normal(mean=mean_vec, cov=cov_mat)\n",
    "        U_a_list.append(Ua)\n",
    "\n",
    "        # Transform to Gumbel-based eta^(a)\n",
    "        eta_a = np.zeros_like(Ua)\n",
    "        for i_loc, j_global in enumerate(Ma):\n",
    "            # step 1: Gaussian -> Uniform(0,1)\n",
    "            p_vec = norm.cdf(Ua[i_loc, :])\n",
    "            # step 2: Uniform(0,1) -> Gumbel -> + alpha\n",
    "            gumbel_vec = np.array([G_inv(p) for p in p_vec])\n",
    "            eta_a[i_loc, :] = gumbel_vec + alpha[j_global]\n",
    "        eta_a_list.append(eta_a)\n",
    "\n",
    "        # partial order h^(a)\n",
    "        h_a = BasicUtils.generate_partial_order(eta_a)\n",
    "        h_a_list.append(h_a)\n",
    "\n",
    "        # Restrict partial order to each choice set O_{a,i}\n",
    "        O_list = O_a_i_dict.get(a, [])\n",
    "        for i_task, subset in enumerate(O_list):\n",
    "            subset_indices_in_Ma = []\n",
    "            for item_j in subset:\n",
    "                if item_j in Ma:\n",
    "                    local_idx = Ma.index(item_j)\n",
    "                    subset_indices_in_Ma.append(local_idx)\n",
    "\n",
    "            sub_size = len(subset_indices_in_Ma)\n",
    "            h_sub = np.zeros((sub_size, sub_size), dtype=int)\n",
    "            for r, i_loc_ in enumerate(subset_indices_in_Ma):\n",
    "                for c, j_loc_ in enumerate(subset_indices_in_Ma):\n",
    "                    h_sub[r, c] = h_a[i_loc_, j_loc_]\n",
    "            \n",
    "            h_a_i[a][i_task] = h_sub\n",
    "\n",
    "    # ----------------------------\n",
    "    # Return results\n",
    "    # ----------------------------\n",
    "    results = {\n",
    "        'U0': U0,         # shape (|M0|, K)\n",
    "        'U_a': U_a_list,  # list of length = # of assessors\n",
    "        'eta_a': eta_a_list,\n",
    "        'h_a': h_a_list,\n",
    "        'h_a_i': h_a_i\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulate_HPO_with_tasks(\n",
    "    M0=M0,\n",
    "    assessors=assessors,\n",
    "    M_a_list=M_a_list,\n",
    "    O_a_i_dict=O_a_i_dict,\n",
    "    alpha=alpha,         # Not None\n",
    "    K=2,\n",
    "    rho=0.3,\n",
    "    tau=0.8,\n",
    "    random_seed=2025     # Global random seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Global U^(0) ---\n",
      "[[ 0.48895212 -0.62589801]\n",
      " [ 0.39564124 -1.31760809]\n",
      " [ 1.15817296  1.67569046]\n",
      " [ 0.41622277  0.23918466]\n",
      " [ 0.08670167 -0.88035684]\n",
      " [-0.08601646 -0.18616445]]\n",
      "\n",
      "Assessor 1\n",
      "  U^(a):\n",
      " [[1.45643201 0.58300983]\n",
      " [1.58808047 1.20044712]\n",
      " [0.97889183 0.74861902]]\n",
      "  eta^(a):\n",
      " [[3.08481816 1.61344563]\n",
      " [3.15126579 2.40251959]\n",
      " [1.72088666 1.35660968]]\n",
      "  h^(a) adjacency:\n",
      " [[0 0 1]\n",
      " [1 0 1]\n",
      " [0 0 0]]\n",
      "  Task 0, O_(1, 0) = [0, 2, 4]\n",
      "    restricted adjacency:\n",
      " [[0 0 1]\n",
      " [1 0 1]\n",
      " [0 0 0]]\n",
      "  Task 1, O_(1, 1) = [0, 2]\n",
      "    restricted adjacency:\n",
      " [[0 0]\n",
      " [1 0]]\n",
      "\n",
      "Assessor 2\n",
      "  U^(a):\n",
      " [[ 0.58923709 -0.59181387]\n",
      " [ 0.4833693   1.10476886]\n",
      " [ 0.19496226  0.52101298]]\n",
      "  eta^(a):\n",
      " [[ 0.92231923 -0.44981078]\n",
      " [ 1.27422345  2.23379796]\n",
      " [ 0.69890539  1.12621594]]\n",
      "  h^(a) adjacency:\n",
      " [[0 0 0]\n",
      " [1 0 1]\n",
      " [0 0 0]]\n",
      "  Task 0, O_(2, 0) = [1, 2, 5]\n",
      "    restricted adjacency:\n",
      " [[0 0]\n",
      " [1 0]]\n",
      "  Task 1, O_(2, 1) = [1, 3]\n",
      "    restricted adjacency:\n",
      " [[0 0]\n",
      " [0 0]]\n",
      "  Task 2, O_(2, 2) = [1, 4, 5]\n",
      "    restricted adjacency:\n",
      " [[0]]\n",
      "\n",
      "Assessor 3\n",
      "  U^(a):\n",
      " [[-0.14763682 -1.09298036]\n",
      " [ 1.27120912  0.85097338]\n",
      " [-0.64517687  0.6655372 ]]\n",
      "  eta^(a):\n",
      " [[ 8.96536820e-04 -8.86277003e-01]\n",
      " [ 2.33126284e+00  1.61463267e+00]\n",
      " [-2.99630237e-01  1.23273597e+00]]\n",
      "  h^(a) adjacency:\n",
      " [[0 0 0]\n",
      " [1 0 1]\n",
      " [0 0 0]]\n",
      "  Task 0, O_(3, 0) = [1, 3]\n",
      "    restricted adjacency:\n",
      " [[0 0]\n",
      " [1 0]]\n",
      "  Task 1, O_(3, 1) = [1, 3, 4]\n",
      "    restricted adjacency:\n",
      " [[0 0 0]\n",
      " [1 0 1]\n",
      " [0 0 0]]\n",
      "  Task 2, O_(3, 2) = [2, 4, 5]\n",
      "    restricted adjacency:\n",
      " [[0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Global U^(0) ---\")\n",
    "print(results['U0'])\n",
    "\n",
    "for idx, a in enumerate(assessors):\n",
    "    print(f\"\\nAssessor {a}\")\n",
    "    print(\"  U^(a):\\n\", results['U_a'][idx])\n",
    "    print(\"  eta^(a):\\n\", results['eta_a'][idx])\n",
    "    print(\"  h^(a) adjacency:\\n\", results['h_a'][idx])\n",
    "\n",
    "    # Show restricted partial orders\n",
    "    for i_task, O_subset in enumerate(O_a_i_dict[a]):\n",
    "        print(f\"  Task {i_task}, O_{a,i_task} = {O_subset}\")\n",
    "        print(\"    restricted adjacency:\\n\", results['h_a_i'][a][i_task])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-partial-orders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
